{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial with examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmfa.fluxomics_data.reaction import Reaction\n",
    "from cmfa.fluxomics_data.reaction_network import ReactionNetwork\n",
    "from cmfa.data_preparation import import_fluxomics_dataset_from_json\n",
    "from cmfa.fluxomics_data.compound import AtomPattern\n",
    "from cmfa.fluxomics_data.emu import EMU, EMUReaction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/te/Library/CloudStorage/OneDrive-Personal/Biosustain/cmfa/cmfa/../data/test_data'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "CUR_DIR = os.getcwd()\n",
    "TEST_DIR = f'{CUR_DIR}/../data/test_data'\n",
    "\n",
    "TEST_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = import_fluxomics_dataset_from_json(f'{TEST_DIR}/model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reaction id=R4, name=R4,stoichiometry={'B': {abc: -1.0}, 'C': {de: -1.0}, 'D': {bcd: 1.0}, 'E': {a: 1.0, e: 1.0}},reversible=False, "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.reaction_network.R4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compound           A         B     C         D               E           F\n",
      "pattern          abc       abc    bc  de   abc   bcd         a     e   abc\n",
      "compound pattern                                                          \n",
      "A        abc      []      [R1]    []  []    []    []        []    []    []\n",
      "B        abc      []        []  [R3]  []  [R2]  [R4]  [R4, R3]    []    []\n",
      "C        bc       []        []    []  []    []    []        []    []    []\n",
      "         de       []        []    []  []    []  [R4]        []  [R4]    []\n",
      "D        abc      []  [R2_rev]    []  []    []    []        []    []  [R5]\n",
      "         bcd      []        []    []  []    []    []        []    []    []\n",
      "E        a        []        []    []  []    []    []        []    []    []\n",
      "         e        []        []    []  []    []    []        []    []    []\n",
      "F        abc      []        []    []  []    []    []        []    []    []\n"
     ]
    }
   ],
   "source": [
    "print(model.reaction_network.reaction_adjacency_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D bcd 12\n",
      "E a 1\n",
      "E e \n",
      "{'B': {'123': 1.0}, 'D': {'12': -1.0}, 'E': {'1': -1.0}}\n",
      "([reaction id: R4, EMU stoichiometry: {'B': {'123': 1.0}, 'D': {'12': -1.0}, 'E': {'1': -1.0}}], {EMU id: E_1, compound id: E, atom pattern: (1,), EMU id: D_12, compound id: D, atom pattern: (1, 2)})\n"
     ]
    }
   ],
   "source": [
    "def atom_mapping_to_reaction(emu: EMU, reaction: Reaction, reverse: bool=False) -> list:\n",
    "    \"\"\"\n",
    "    Given an EMU and reaction information, returns an EMUReaction object.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        atom_transitions = reaction.stoichiometry_input[emu.compound].keys()\n",
    "    except:\n",
    "        raise ValueError(f\"Cannot find the EMU compound in the corresponding reaction\")\n",
    "\n",
    "    emu_reactions = []\n",
    "    # Use emu to find matching atoms in given compounds.\n",
    "    # TODO: What if the emu matches two same compounds in reaction\n",
    "    for transition in atom_transitions:\n",
    "        adjusted_indices = [i - 1 for i in emu.atom_number]\n",
    "        try:\n",
    "            matched_atoms = ''.join(transition[i] for i in adjusted_indices)\n",
    "        except:\n",
    "            raise ValueError(f\"Cannot find atoms in compound {emu.compound} with indices {emu.atom_number_input}\")\n",
    "\n",
    "        # Extracting the stoichiometry for the specific EMU\n",
    "        emu_stoichiometry = {}\n",
    "        emu_reactants = set()\n",
    "        for cpd, stoich in reaction.stoichiometry_input.items():\n",
    "            new_stoich = {}\n",
    "            for pattern, coeff in stoich.items():\n",
    "                if cpd == emu.compound: # Add the original EMU\n",
    "                    new_stoich[emu.atom_number_input] = coeff * (-1 if reverse else 1)\n",
    "                    emu_stoichiometry[cpd] = new_stoich\n",
    "\n",
    "                elif (not reverse and coeff < 0) or (reverse and reaction.reversible and coeff > 0):\n",
    "                    # For matched reactants or products in reverse reaction\n",
    "                    reactant_matched_atom_number = _find_matchable_atoms(pattern, matched_atoms)\n",
    "                    if len(reactant_matched_atom_number) != 0:\n",
    "                        emu_id = f\"{cpd}_{reactant_matched_atom_number}\"\n",
    "                        emu_reactants.add(EMU(id=emu_id, compound=cpd, atom_number_input=reactant_matched_atom_number))\n",
    "                        emu_stoichiometry.setdefault(cpd, {})[reactant_matched_atom_number] = -coeff if reverse else coeff\n",
    "\n",
    "        emu_reactions.append(EMUReaction(reaction_id=reaction.id, emu_stoichiometry=emu_stoichiometry))\n",
    "\n",
    "    return emu_reactions, set(emu_reactants)\n",
    "\n",
    "def _find_matchable_atoms(pattern: str, matched_atoms: str):\n",
    "    \n",
    "    \"\"\"\n",
    "    Finds matchable atoms between a pattern and matched_atoms, returning the positions as a string.\n",
    "    \"\"\"\n",
    "    matched_pattern = [str(pattern.index(char) + 1) for char in matched_atoms if char in pattern]\n",
    "    return ''.join(sorted(matched_pattern))\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "product_emu = EMU(id=\"B_123\", compound=\"B\", atom_number_input=\"123\")\n",
    "reaction = Reaction(id='R4', name='R4', stoichiometry_input={'B': {\"abc\": -1.0}, 'C': {\"de\": -1.0}, 'D': {\"bcd\": 1.0}, 'E': {\"a\": 1.0, \"e\": 1.0}}, reversible=True)\n",
    "\n",
    "emu_reaction = atom_mapping_to_reaction(product_emu, reaction, reverse=True)\n",
    "print(emu_reaction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_participated_reactions(cur_emu, MAM):\n",
    "    \"\"\"\n",
    "    Identifies the reactions in which a given EMU participates within the Metabolite Adjacency Matrix (MAM).\n",
    "    \n",
    "    Parameters:\n",
    "    - MAM: DataFrame representing the Metabolite Adjacency Matrix with multi-index columns.\n",
    "    - cur_emu: The current EMU object, expected to have at least a 'compound' attribute.\n",
    "    \n",
    "    Returns:\n",
    "    - A DataFrame filtered to show only the reactions (columns) in which the current EMU's compound participates.\n",
    "      The cells are boolean, indicating whether the reaction is non-empty (True) or not (False).\n",
    "    \"\"\"\n",
    "    # Extract reactions for the current EMU's compound\n",
    "    participated_reactions = MAM.xs(cur_emu.compound, level=0, axis=1).map(\n",
    "        lambda x: x if isinstance(x, list) and len(x) > 0 else []\n",
    "    ).sum().tolist()\n",
    "    \n",
    "    return participated_reactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "\n",
    "def decompose_network(\n",
    "    target_EMU: EMU, reaction_network: ReactionNetwork\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return a EMU map based on the target compound from the reaction network. \n",
    "    \"\"\"\n",
    "    MAM = reaction_network.reaction_adjacency_matrix()\n",
    "    queue = deque([target_EMU])\n",
    "    visited = set()\n",
    "    emu_maps = {}\n",
    "\n",
    "    while queue:\n",
    "        # Keep poping new EMU added from previous round.\n",
    "        cur_emu = queue.popleft()\n",
    "        if cur_emu in visited:\n",
    "            continue\n",
    "        visited.add(cur_emu)\n",
    "\n",
    "        # Add new EMU map if the EMU size is not added\n",
    "        emu_size = cur_emu.size\n",
    "        if emu_size not in emu_maps:\n",
    "            emu_maps[emu_size] = {}\n",
    "        \n",
    "        # Find the reaction that is participated in the current emu\n",
    "        participated_reactions = find_participated_reactions(cur_emu, MAM)\n",
    "        new_map = []\n",
    "        for r_list in participated_reactions:\n",
    "            for r in r_list:\n",
    "                # Handle forward and reverse case\n",
    "                if r.endswith('_rev'):\n",
    "                    new_emu_reactions, new_emus = atom_mapping_to_reaction(cur_emu, reaction_network.find_reaction_by_id(r[:-4]), reverse=True)\n",
    "                else:\n",
    "                    new_emu_reactions, new_emus = atom_mapping_to_reaction(cur_emu, reaction_network.find_reaction_by_id(r), reverse=False)\n",
    "                new_map.append(new_emu_reactions)\n",
    "                # TODO: Find equivalent EMUs\n",
    "                for e in new_emus:\n",
    "                    if e not in visited and e not in queue:\n",
    "                        queue.append(e)\n",
    "            \n",
    "        emu_maps[emu_size].setdefault(cur_emu, []).append(new_map)\n",
    "            \n",
    "    return emu_maps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current EMU: F, have visited set()\n",
      "D abc 123\n",
      "{'D': {'123': -1.0}, 'F': {'123': 1.0}}\n",
      "Current EMU: D, have visited {EMU id: F_123, compound id: F, atom pattern: (1, 2, 3)}\n",
      "B abc 123\n",
      "{'B': {'123': -1.0}, 'D': {'123': 1.0}}\n",
      "B abc 23\n",
      "C de 1\n",
      "{'B': {'23': -1.0}, 'C': {'1': -1.0}, 'D': {'123': 1.0}}\n",
      "B abc 23\n",
      "C de 1\n",
      "{'B': {'23': -1.0}, 'C': {'1': -1.0}, 'D': {'123': 1.0}}\n",
      "Current EMU: B, have visited {EMU id: F_123, compound id: F, atom pattern: (1, 2, 3), EMU id: D_123, compound id: D, atom pattern: (1, 2, 3)}\n",
      "A abc 123\n",
      "{'A': {'123': -1.0}, 'B': {'123': 1.0}}\n",
      "D abc 123\n",
      "{'B': {'123': 1.0}, 'D': {'123': -1.0}}\n",
      "Current EMU: B, have visited {EMU id: F_123, compound id: F, atom pattern: (1, 2, 3), EMU id: B_123, compound id: B, atom pattern: (1, 2, 3), EMU id: D_123, compound id: D, atom pattern: (1, 2, 3)}\n",
      "A abc 23\n",
      "{'A': {'23': -1.0}, 'B': {'23': 1.0}}\n",
      "D abc 23\n",
      "{'B': {'23': 1.0}, 'D': {'23': -1.0}}\n",
      "Current EMU: C, have visited {EMU id: F_123, compound id: F, atom pattern: (1, 2, 3), EMU id: B_23, compound id: B, atom pattern: (2, 3), EMU id: B_123, compound id: B, atom pattern: (1, 2, 3), EMU id: D_123, compound id: D, atom pattern: (1, 2, 3)}\n",
      "B abc 2\n",
      "{'B': {'2': -1.0}, 'C': {'1': 1.0}}\n",
      "Current EMU: A, have visited {EMU id: F_123, compound id: F, atom pattern: (1, 2, 3), EMU id: C_1, compound id: C, atom pattern: (1,), EMU id: D_123, compound id: D, atom pattern: (1, 2, 3), EMU id: B_23, compound id: B, atom pattern: (2, 3), EMU id: B_123, compound id: B, atom pattern: (1, 2, 3)}\n",
      "Current EMU: A, have visited {EMU id: F_123, compound id: F, atom pattern: (1, 2, 3), EMU id: A_123, compound id: A, atom pattern: (1, 2, 3), EMU id: C_1, compound id: C, atom pattern: (1,), EMU id: D_123, compound id: D, atom pattern: (1, 2, 3), EMU id: B_23, compound id: B, atom pattern: (2, 3), EMU id: B_123, compound id: B, atom pattern: (1, 2, 3)}\n",
      "Current EMU: D, have visited {EMU id: F_123, compound id: F, atom pattern: (1, 2, 3), EMU id: A_123, compound id: A, atom pattern: (1, 2, 3), EMU id: C_1, compound id: C, atom pattern: (1,), EMU id: D_123, compound id: D, atom pattern: (1, 2, 3), EMU id: B_23, compound id: B, atom pattern: (2, 3), EMU id: B_123, compound id: B, atom pattern: (1, 2, 3), EMU id: A_23, compound id: A, atom pattern: (2, 3)}\n",
      "B abc 23\n",
      "{'B': {'23': -1.0}, 'D': {'23': 1.0}}\n",
      "B abc 3\n",
      "C de 1\n",
      "{'B': {'3': -1.0}, 'C': {'1': -1.0}, 'D': {'23': 1.0}}\n",
      "B abc 3\n",
      "C de 1\n",
      "{'B': {'3': -1.0}, 'C': {'1': -1.0}, 'D': {'23': 1.0}}\n",
      "Current EMU: B, have visited {EMU id: F_123, compound id: F, atom pattern: (1, 2, 3), EMU id: A_123, compound id: A, atom pattern: (1, 2, 3), EMU id: C_1, compound id: C, atom pattern: (1,), EMU id: D_123, compound id: D, atom pattern: (1, 2, 3), EMU id: B_23, compound id: B, atom pattern: (2, 3), EMU id: B_123, compound id: B, atom pattern: (1, 2, 3), EMU id: A_23, compound id: A, atom pattern: (2, 3), EMU id: D_23, compound id: D, atom pattern: (2, 3)}\n",
      "A abc 2\n",
      "{'A': {'2': -1.0}, 'B': {'2': 1.0}}\n",
      "D abc 2\n",
      "{'B': {'2': 1.0}, 'D': {'2': -1.0}}\n",
      "Current EMU: B, have visited {EMU id: F_123, compound id: F, atom pattern: (1, 2, 3), EMU id: A_123, compound id: A, atom pattern: (1, 2, 3), EMU id: C_1, compound id: C, atom pattern: (1,), EMU id: D_123, compound id: D, atom pattern: (1, 2, 3), EMU id: B_2, compound id: B, atom pattern: (2,), EMU id: B_23, compound id: B, atom pattern: (2, 3), EMU id: B_123, compound id: B, atom pattern: (1, 2, 3), EMU id: A_23, compound id: A, atom pattern: (2, 3), EMU id: D_23, compound id: D, atom pattern: (2, 3)}\n",
      "A abc 3\n",
      "{'A': {'3': -1.0}, 'B': {'3': 1.0}}\n",
      "D abc 3\n",
      "{'B': {'3': 1.0}, 'D': {'3': -1.0}}\n",
      "Current EMU: A, have visited {EMU id: F_123, compound id: F, atom pattern: (1, 2, 3), EMU id: A_123, compound id: A, atom pattern: (1, 2, 3), EMU id: C_1, compound id: C, atom pattern: (1,), EMU id: D_123, compound id: D, atom pattern: (1, 2, 3), EMU id: B_2, compound id: B, atom pattern: (2,), EMU id: B_23, compound id: B, atom pattern: (2, 3), EMU id: B_123, compound id: B, atom pattern: (1, 2, 3), EMU id: A_23, compound id: A, atom pattern: (2, 3), EMU id: D_23, compound id: D, atom pattern: (2, 3), EMU id: B_3, compound id: B, atom pattern: (3,)}\n",
      "Current EMU: D, have visited {EMU id: F_123, compound id: F, atom pattern: (1, 2, 3), EMU id: A_123, compound id: A, atom pattern: (1, 2, 3), EMU id: C_1, compound id: C, atom pattern: (1,), EMU id: D_123, compound id: D, atom pattern: (1, 2, 3), EMU id: B_2, compound id: B, atom pattern: (2,), EMU id: B_23, compound id: B, atom pattern: (2, 3), EMU id: A_2, compound id: A, atom pattern: (2,), EMU id: B_123, compound id: B, atom pattern: (1, 2, 3), EMU id: A_23, compound id: A, atom pattern: (2, 3), EMU id: D_23, compound id: D, atom pattern: (2, 3), EMU id: B_3, compound id: B, atom pattern: (3,)}\n",
      "B abc 2\n",
      "{'B': {'2': -1.0}, 'D': {'2': 1.0}}\n",
      "B abc 3\n",
      "C de \n",
      "{'B': {'3': -1.0}, 'D': {'2': 1.0}}\n",
      "B abc 3\n",
      "C de \n",
      "{'B': {'3': -1.0}, 'D': {'2': 1.0}}\n",
      "Current EMU: A, have visited {EMU id: F_123, compound id: F, atom pattern: (1, 2, 3), EMU id: A_123, compound id: A, atom pattern: (1, 2, 3), EMU id: C_1, compound id: C, atom pattern: (1,), EMU id: D_123, compound id: D, atom pattern: (1, 2, 3), EMU id: B_2, compound id: B, atom pattern: (2,), EMU id: B_23, compound id: B, atom pattern: (2, 3), EMU id: A_2, compound id: A, atom pattern: (2,), EMU id: B_123, compound id: B, atom pattern: (1, 2, 3), EMU id: A_23, compound id: A, atom pattern: (2, 3), EMU id: D_2, compound id: D, atom pattern: (2,), EMU id: D_23, compound id: D, atom pattern: (2, 3), EMU id: B_3, compound id: B, atom pattern: (3,)}\n",
      "Current EMU: D, have visited {EMU id: F_123, compound id: F, atom pattern: (1, 2, 3), EMU id: A_123, compound id: A, atom pattern: (1, 2, 3), EMU id: A_3, compound id: A, atom pattern: (3,), EMU id: C_1, compound id: C, atom pattern: (1,), EMU id: D_123, compound id: D, atom pattern: (1, 2, 3), EMU id: B_2, compound id: B, atom pattern: (2,), EMU id: B_23, compound id: B, atom pattern: (2, 3), EMU id: A_2, compound id: A, atom pattern: (2,), EMU id: B_123, compound id: B, atom pattern: (1, 2, 3), EMU id: A_23, compound id: A, atom pattern: (2, 3), EMU id: D_2, compound id: D, atom pattern: (2,), EMU id: D_23, compound id: D, atom pattern: (2, 3), EMU id: B_3, compound id: B, atom pattern: (3,)}\n",
      "B abc 3\n",
      "{'B': {'3': -1.0}, 'D': {'3': 1.0}}\n",
      "B abc \n",
      "C de 1\n",
      "{'C': {'1': -1.0}, 'D': {'3': 1.0}}\n",
      "B abc \n",
      "C de 1\n",
      "{'C': {'1': -1.0}, 'D': {'3': 1.0}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{3: {EMU id: F_123, compound id: F, atom pattern: (1, 2, 3): [[[reaction id: R5, EMU stoichiometry: {'D': {'123': -1.0}, 'F': {'123': 1.0}}]]],\n",
       "  EMU id: D_123, compound id: D, atom pattern: (1, 2, 3): [[[reaction id: R2, EMU stoichiometry: {'B': {'123': -1.0}, 'D': {'123': 1.0}}],\n",
       "    [reaction id: R4, EMU stoichiometry: {'B': {'23': -1.0}, 'C': {'1': -1.0}, 'D': {'123': 1.0}}],\n",
       "    [reaction id: R4, EMU stoichiometry: {'B': {'23': -1.0}, 'C': {'1': -1.0}, 'D': {'123': 1.0}}]]],\n",
       "  EMU id: B_123, compound id: B, atom pattern: (1, 2, 3): [[[reaction id: R1, EMU stoichiometry: {'A': {'123': -1.0}, 'B': {'123': 1.0}}],\n",
       "    [reaction id: R2, EMU stoichiometry: {'B': {'123': 1.0}, 'D': {'123': -1.0}}]]],\n",
       "  EMU id: A_123, compound id: A, atom pattern: (1, 2, 3): [[]]},\n",
       " 2: {EMU id: B_23, compound id: B, atom pattern: (2, 3): [[[reaction id: R1, EMU stoichiometry: {'A': {'23': -1.0}, 'B': {'23': 1.0}}],\n",
       "    [reaction id: R2, EMU stoichiometry: {'B': {'23': 1.0}, 'D': {'23': -1.0}}]]],\n",
       "  EMU id: A_23, compound id: A, atom pattern: (2, 3): [[]],\n",
       "  EMU id: D_23, compound id: D, atom pattern: (2, 3): [[[reaction id: R2, EMU stoichiometry: {'B': {'23': -1.0}, 'D': {'23': 1.0}}],\n",
       "    [reaction id: R4, EMU stoichiometry: {'B': {'3': -1.0}, 'C': {'1': -1.0}, 'D': {'23': 1.0}}],\n",
       "    [reaction id: R4, EMU stoichiometry: {'B': {'3': -1.0}, 'C': {'1': -1.0}, 'D': {'23': 1.0}}]]]},\n",
       " 1: {EMU id: C_1, compound id: C, atom pattern: (1,): [[[reaction id: R3, EMU stoichiometry: {'B': {'2': -1.0}, 'C': {'1': 1.0}}]]],\n",
       "  EMU id: B_2, compound id: B, atom pattern: (2,): [[[reaction id: R1, EMU stoichiometry: {'A': {'2': -1.0}, 'B': {'2': 1.0}}],\n",
       "    [reaction id: R2, EMU stoichiometry: {'B': {'2': 1.0}, 'D': {'2': -1.0}}]]],\n",
       "  EMU id: B_3, compound id: B, atom pattern: (3,): [[[reaction id: R1, EMU stoichiometry: {'A': {'3': -1.0}, 'B': {'3': 1.0}}],\n",
       "    [reaction id: R2, EMU stoichiometry: {'B': {'3': 1.0}, 'D': {'3': -1.0}}]]],\n",
       "  EMU id: A_2, compound id: A, atom pattern: (2,): [[]],\n",
       "  EMU id: D_2, compound id: D, atom pattern: (2,): [[[reaction id: R2, EMU stoichiometry: {'B': {'2': -1.0}, 'D': {'2': 1.0}}],\n",
       "    [reaction id: R4, EMU stoichiometry: {'B': {'3': -1.0}, 'D': {'2': 1.0}}],\n",
       "    [reaction id: R4, EMU stoichiometry: {'B': {'3': -1.0}, 'D': {'2': 1.0}}]]],\n",
       "  EMU id: A_3, compound id: A, atom pattern: (3,): [[]],\n",
       "  EMU id: D_3, compound id: D, atom pattern: (3,): [[[reaction id: R2, EMU stoichiometry: {'B': {'3': -1.0}, 'D': {'3': 1.0}}],\n",
       "    [reaction id: R4, EMU stoichiometry: {'C': {'1': -1.0}, 'D': {'3': 1.0}}],\n",
       "    [reaction id: R4, EMU stoichiometry: {'C': {'1': -1.0}, 'D': {'3': 1.0}}]]]}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_emu = EMU(id='F_123', compound='F', atom_number_input='123')\n",
    "decompose_network(f_emu, model.reaction_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['R2_f'], ['R4', 'R4']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAM = model.reaction_network.reaction_adjacency_matrix()\n",
    "\n",
    "participated_reactions = MAM.xs('D', level=0, axis=1).map(\n",
    "    lambda x: x if isinstance(x, list) and len(x) > 0 else []\n",
    ").sum().tolist()\n",
    "\n",
    "participated_reactions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative method from freeflux\n",
    "import numpy as np\n",
    "def decompose_network(ini_emus, lump = True, n_jobs = 1):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    ini_emus: dict\n",
    "        Metabolite ID => atom NOs or list of atom NOs. Atom NOs can be int list or str, \n",
    "        e.g., {'Ala': [[1,2,3], '23'], 'Ser': '123'}\n",
    "    lump: bool\n",
    "        Whether to lump linear EMUs.\n",
    "    n_jobs: int\n",
    "        # of jobs to run in parallel.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    mergedEAMs: dict of df\n",
    "        Size => merged EMU adjacency matrix (EAM)\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    EMUs in sequential reactions can not be lumped in transient MFA.      \n",
    "    '''\n",
    "    \n",
    "    metabids = []\n",
    "    atom_nos = []\n",
    "    for metabid, atomNOs in ini_emus.items():\n",
    "        if isinstance(atomNOs, list):\n",
    "            if any(isinstance(item, Iterable) for item in atomNOs):\n",
    "                for atomnos in atomNOs:\n",
    "                    if not isinstance(atomnos, str):\n",
    "                        atomnos = ''.join(map(str, atomnos))\n",
    "                    metabids.append(metabid)\n",
    "                    atom_nos.append(atomnos)\n",
    "            else:\n",
    "                atomNOs = ''.join(map(str, atomNOs))\n",
    "                metabids.append(metabid)\n",
    "                atom_nos.append(atomnos)\n",
    "        else:\n",
    "            metabids.append(metabid)\n",
    "            atom_nos.append(atomNOs)            \n",
    "    \n",
    "    return _decompose_network(metabids, atom_nos, lump = lump, n_jobs = n_jobs) \n",
    "\n",
    "\n",
    "def _decompose_network(metabolites, atom_nos, lump = True):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    metabolites: list of str\n",
    "        List of metabolite IDs from which initial EMU will be generated to start the \n",
    "        decomposition.\n",
    "    atom_nos: list of str\n",
    "        Atom NOs of corresponding metabolites, len(atom_nos) should be equal to \n",
    "        len(metabolites).\n",
    "    lump: bool\n",
    "        Whether to lump linear EMUs.    \n",
    "    n_jobs: int\n",
    "        # of jobs to run in parallel.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    mergedEAMs: dict of df\n",
    "        Size => merged EMU adjacency matrix (EAM).\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    EMUs in sequential reactions can not be lumped in transient MFA.    \n",
    "    '''\n",
    "    \n",
    "    emus = []\n",
    "    for metabid, atomNOs in zip(metabolites, atom_nos):\n",
    "        emus.append(EMU(metabid+'_'+atomNOs, Metabolite(metabid), atomNOs))\n",
    "        \n",
    "    EAMsAll = []\n",
    "    for emu in emus:\n",
    "        EAMs = get_emu_adjacency_matrices(emu, lump)\n",
    "        EAMsAll.append(EAMs)\n",
    "    \n",
    "    mergedEAMs = _merge_all_EAMs(*EAMsAll)\n",
    "    \n",
    "    return mergedEAMs\n",
    "\n",
    "def _merge_all_EAMs(self, *EAMsAll):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    EAMsAll: tuple of EAMs\n",
    "        EAMs is dict of DataFrame, i.e., Size => EMU adjacency matrix (EAM).\n",
    "\n",
    "    Returns\n",
    "    -------    \n",
    "    mergedEAMs: dict of df\n",
    "        Size => merged EAM     \n",
    "    '''\n",
    "    \n",
    "    mergedEAMs = {}\n",
    "    maxsize = max([max(EAMs) for EAMs in EAMsAll])\n",
    "    for size in range(1, maxsize+1):\n",
    "        EAMCurrentSize = list(\n",
    "            filter(\n",
    "                lambda x: isinstance(x, pd.DataFrame), \n",
    "                [EAMs.get(size, 0) for EAMs in EAMsAll]\n",
    "            )\n",
    "        )\n",
    "        if EAMCurrentSize:   \n",
    "            mergedEAMs[size] = reduce(self._merge_EAMs, EAMCurrentSize)\n",
    "    \n",
    "    return mergedEAMs            \n",
    "\n",
    "    \n",
    "\n",
    "def get_emu_adjacency_matrices(self, iniEMU, lump = True):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        iniEMU: EMU\n",
    "            Starting EMU of the decomposition.\n",
    "        lump: bool\n",
    "            Whether to lump linear EMUs.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        EAMs: dict of df\n",
    "            Size => EMU adjacency matrix (EAM) after lumping of linear EMUs and combination\n",
    "            of equivalent EMUs. Index and columns are EMUs, cells are symbolic expression of flux.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        EMUs in sequential reactions can not be lumped in transient MFA.\n",
    "        '''\n",
    "            \n",
    "        oriEAMs = _get_original_EAMs(iniEMU)\n",
    "        \n",
    "        if lump:\n",
    "            lumpedEAMs = _lump_linear_EMUs(oriEAMs, iniEMU)\n",
    "            combinedEAMs = _combine_equivalent_EMUs(lumpedEAMs)\n",
    "        else:\n",
    "            combinedEAMs = _combine_equivalent_EMUs(oriEAMs)\n",
    "        \n",
    "        return combinedEAMs\n",
    "\n",
    "def _get_original_EAMs(self, iniEMU):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        iniEMU: EMU\n",
    "            Starting EMU of the decomposition.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        EAMs: dict of df\n",
    "            Size => original EMU adjacency matrix (EAM), cells are symbolic expression of fluxã€‚\n",
    "        '''\n",
    "        \n",
    "        EAMsInfo = _BFS(iniEMU)\n",
    "        \n",
    "        EAMs = {}\n",
    "        for size, EMUsInfo in EAMsInfo.items():\n",
    "            \n",
    "            nonSourceEMUs = set([EMUInfo[0] for EMUInfo in EMUsInfo])\n",
    "            SourceEMUs = sorted(\n",
    "                set(\n",
    "                    [tuple(EMUInfo[1]) if len(EMUInfo[1]) > 1 else EMUInfo[1][0] \n",
    "                     for EMUInfo in EMUsInfo]\n",
    "                ) - nonSourceEMUs\n",
    "            )\n",
    "            \n",
    "            EAM = pd.DataFrame(\n",
    "                Integer(0), \n",
    "                index = sorted(nonSourceEMUs) + sorted(SourceEMUs), \n",
    "                columns = sorted(nonSourceEMUs)\n",
    "            )\n",
    "            for emu, preEMUs, flux in EMUsInfo:\n",
    "                \n",
    "                col = emu\n",
    "                \n",
    "                if len(preEMUs) == 1:\n",
    "                    idx = preEMUs[0]\n",
    "                else:\n",
    "                    idx = tuple(preEMUs)\n",
    "                \n",
    "                EAM.loc[[idx], col] += flux   \n",
    "            \n",
    "            EAMs[size] = EAM\n",
    "        \n",
    "        return EAMs\n",
    "\n",
    "def _BFS(self, iniEMU):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        iniEMU: EMU\n",
    "            Starting EMU of the decomposition. \n",
    "            Metabolite of iniEMU can be any Metabolite instance with the same id.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        EAMsInfo: dict of list\n",
    "            Size => list of [EMU, [precursor EMUs], symbolic expression of flux].\n",
    "        '''\n",
    "        \n",
    "        MAM = self.metabolite_adjacency_matrix\n",
    "        \n",
    "        EAMsInfo = {}\n",
    "        \n",
    "        searched = []\n",
    "        toSearch = deque()\n",
    "        toSearch.appendleft(iniEMU)\n",
    "        while toSearch:\n",
    "            \n",
    "            currentEMU = toSearch.pop()\n",
    "            searched.append(currentEMU)\n",
    "                    \n",
    "            formingRxns = list(\n",
    "                set(chain(*[cell for cell in MAM[currentEMU.metabolite_id] if cell]))\n",
    "            )   \n",
    "            for formingRxn in formingRxns:\n",
    "                \n",
    "                if formingRxn.reversible:\n",
    "                    if currentEMU.metabolite_id in formingRxn.products_with_atoms:\n",
    "                        asProMetabs = formingRxn.products_info['metab'][currentEMU.metabolite_id]\n",
    "                        direction = 'forward'\n",
    "                        flux = formingRxn.fflux\n",
    "                    else:\n",
    "                        asProMetabs = formingRxn.substrates_info['metab'][currentEMU.metabolite_id]\n",
    "                        direction = 'backward'\n",
    "                        flux = formingRxn.bflux\n",
    "                else:\n",
    "                    asProMetabs = formingRxn.products_info['metab'][currentEMU.metabolite_id]\n",
    "                    direction = 'forward'\n",
    "                    flux = formingRxn.flux\n",
    "                \n",
    "                if isinstance(asProMetabs, pd.Series):\n",
    "                    offset = 1/asProMetabs.size\n",
    "                    asProMetabs = list(asProMetabs)\n",
    "                else:\n",
    "                    offset = 1.0\n",
    "                    asProMetabs = [asProMetabs]\n",
    "                \n",
    "                \n",
    "                for asProMetab in asProMetabs:    \n",
    "                    currentEMU = EMU(currentEMU.id, asProMetab, currentEMU.atom_nos)   \n",
    "                    preEMUsInfo = formingRxn._find_precursor_EMUs(currentEMU, direction = direction)\n",
    "                    \n",
    "                    for preEMUs, coe in preEMUsInfo:\n",
    "                        for preEMU in preEMUs:\n",
    "                            if preEMU not in searched and preEMU not in toSearch:\n",
    "                                toSearch.appendleft(preEMU)\n",
    "                            \n",
    "                        EAMsInfo.setdefault(currentEMU.size, []).append(\n",
    "                            [currentEMU, preEMUs, offset * coe * flux]\n",
    "                        )\n",
    "                            \n",
    "        return EAMsInfo\n",
    "\n",
    "def _find_precursor_EMUs(self, emu, direction = 'forward'):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    emu: EMU\n",
    "    direction: str\n",
    "        * For reversible reaction,\n",
    "        'forward' if emu is product and precursor emu(s) are substrates;\n",
    "        'backward' if emu is substrate and precursor emu(s) are products.\n",
    "        * For irreversible reaction, only 'forward' is acceptable.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    preEMUsInfo: list\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    For reaction like: A({'ab': 0.5, 'ba': 0.5}) + B({'c': 1}) -> C({'abc': 0.5, 'cba': 0.5}),\n",
    "    _find_precursor_EMUs(C12) returns\n",
    "    [[[A_12], 0.5],\n",
    "        [[B_1, A_2], 0.25],\n",
    "        [[B_1, A_1], 0.25]].\n",
    "    '''        \n",
    "    \n",
    "    if self.reversible:\n",
    "        if direction == 'forward':\n",
    "            atomMapping = self._substrates_atom_mapping\n",
    "            reacInfo = self.substrates_info['metab']\n",
    "        \n",
    "        elif direction == 'backward':\n",
    "            atomMapping = self._products_atom_mapping\n",
    "            reacInfo = self.products_info['metab']\n",
    "    \n",
    "    else:\n",
    "        if direction != 'forward':\n",
    "            raise ValueError('only \"forward\" is acceptable for irreversible reaction')\n",
    "        \n",
    "        atomMapping = self._substrates_atom_mapping\n",
    "        reacInfo = self.substrates_info['metab']\n",
    "    \n",
    "    \n",
    "    preEMUsInfoRaw = []\n",
    "    for scenario in atomMapping:\n",
    "        for atoms, coe in emu.metabolite.atoms_info.items():   \n",
    "            \n",
    "            preAtoms = {}\n",
    "            uniCoe = coe\n",
    "            for atom in [atoms[no-1] for no in emu.atom_nos]:\n",
    "                \n",
    "                pre, preAtomNO, preCoe = scenario[atom]   \n",
    "                \n",
    "                if pre not in preAtoms:\n",
    "                    uniCoe *= preCoe\n",
    "                    preAtoms[pre] = [preAtomNO]\n",
    "                else:\n",
    "                    preAtoms[pre].append(preAtomNO)\n",
    "            \n",
    "            preEMUs = [EMU(pre.id+'_'+''.join(map(str, sorted(preAtomNOs))), pre, preAtomNOs) \n",
    "                        for pre, preAtomNOs in preAtoms.items()]\n",
    "            preEMUsInfoRaw.append([preEMUs, uniCoe])\n",
    "    \n",
    "    preEMUsInfoRaw = [Counter({tuple(sorted(preEMUs)): coe}) \n",
    "                        for preEMUs, coe in preEMUsInfoRaw]   \n",
    "    preEMUsInfo = reduce(lambda x, y: x+y, preEMUsInfoRaw) \n",
    "    preEMUsInfo = [[list(preEMUs), coe] for preEMUs, coe in preEMUsInfo.items()]\n",
    "    \n",
    "    return preEMUsInfo\n",
    "    \n",
    "\n",
    "def _lump_linear_EMUs(self, EAMs, iniEMU):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    EAMs: dict of df\n",
    "        Size => original EMU adjacency matrix (EAM), cells are symbolic expression of flux.\n",
    "    iniEMU: EMU\n",
    "        Starting EMU of the decomposition.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    lumpedEAMs: dict of df\n",
    "        Size => lumped EMU adjacency matrix (EAM), cells are symbolic expression of flux.\n",
    "    '''\n",
    "    \n",
    "    lumpedEAMs = {}\n",
    "    orderedSizes = sorted(EAMs.keys(), reverse = True)\n",
    "    for i, size in enumerate(orderedSizes):\n",
    "        \n",
    "        lumpedEAM = EAMs[size].copy(deep = 'all')\n",
    "        for emu in lumpedEAM.columns:\n",
    "            \n",
    "            preEMUs = lumpedEAM.index[lumpedEAM[emu] != 0]\n",
    "            if preEMUs.size == 1:   \n",
    "                preEMU = preEMUs[0]\n",
    "                \n",
    "                if (emu != iniEMU and \n",
    "                    (preEMU not in lumpedEAM.columns or lumpedEAM.loc[emu, preEMU] == 0)):\n",
    "                    \n",
    "                    lumpedEAM.drop(emu, axis = 1, inplace = True)\n",
    "                    \n",
    "                    lumpedEAM.index = self._replace_list_item(lumpedEAM.index, emu, preEMU)\n",
    "                    \n",
    "                    for j in range(i):   \n",
    "                        largerEAM = lumpedEAMs[orderedSizes[j]]\n",
    "                        largerEAM.index = self._replace_list_item(largerEAM.index, emu, preEMU)\n",
    "                    \n",
    "                    lumpedEAM = _uniquify_dataFrame_index(lumpedEAM)   \n",
    "                    upper = _uniquify_dataFrame_index(\n",
    "                        lumpedEAM.loc[lumpedEAM.columns, :]\n",
    "                    )\n",
    "                    lower = _uniquify_dataFrame_index(\n",
    "                        lumpedEAM.loc[lumpedEAM.index.difference(lumpedEAM.columns),:]\n",
    "                    )\n",
    "                    lumpedEAM = pd.concat((upper, lower))\n",
    "        \n",
    "        lumpedEAMs[size] = lumpedEAM\n",
    "        \n",
    "    return lumpedEAMs\n",
    "    \n",
    "    \n",
    "def _combine_equivalent_EMUs(self, EAMs):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    EAMs: dict of df\n",
    "        Size => original EMU adjacency matrix (EAM), cells are symbolic expression of flux.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    combinedEAMs: dict df\n",
    "        Size => EAM with equivalent EMUs combined, cells are symbolic expression of flux.\n",
    "    '''\n",
    "    \n",
    "    combinedEAMs = {}\n",
    "    for size, EAM in EAMs.items():\n",
    "        \n",
    "        combinedEAM = EAM.copy(deep = 'all')\n",
    "        combined = []\n",
    "        for emu in combinedEAM.columns:\n",
    "            if emu not in combined:\n",
    "                \n",
    "                equivEMU = emu.equivalent\n",
    "                if equivEMU in combinedEAM.columns:   \n",
    "                    \n",
    "                    combinedEAM.loc[:, emu] = combinedEAM.loc[:, [emu, equivEMU]].sum(axis = 1)/2\n",
    "                    combinedEAM.drop(equivEMU, axis = 1, inplace = True)\n",
    "                    \n",
    "                    combinedEAM.loc[emu, :] = combinedEAM.loc[[emu, equivEMU], :].sum()\n",
    "                    combinedEAM.drop(equivEMU, inplace = True)\n",
    "                    \n",
    "                    combined.append(equivEMU)\n",
    "                \n",
    "        combinedEAMs[size] = combinedEAM\n",
    "\n",
    "    return combinedEAMs\n",
    "\n",
    "def _uniquify_dataFrame_index(self, df):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: df\n",
    "        DataFrame to be uniquify.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    uniqueDf: df\n",
    "        DataFrame with duplicate rows combined (summated).\n",
    "    '''\n",
    "    \n",
    "    sortedDf = df.sort_index()\n",
    "\n",
    "    sortDfIndex, idx = np.unique(sortedDf.index, return_index = True)\n",
    "\n",
    "    uniqueDf = pd.DataFrame(\n",
    "        np.add.reduceat(sortedDf.values, idx), \n",
    "        index = sortDfIndex, \n",
    "        columns = sortedDf.columns\n",
    "    )\n",
    "    \n",
    "    return uniqueDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Define the EMU class.'''\n",
    "\n",
    "\n",
    "__author__ = 'Chao Wu'\n",
    "__date__ = '02/26/2022'\n",
    "\n",
    "\n",
    "from functools import lru_cache\n",
    "from collections.abc import Iterable\n",
    "from .metabolite import Metabolite\n",
    "\n",
    "\n",
    "class EMU():\n",
    "    '''\n",
    "    Define EMU (i.e., elementary metabolite unit) object and its operations.\n",
    "\n",
    "    EMUs in the same metabolite and with the same atom NOs are considered as identical, \n",
    "    while metabolites which they derived from could be different.\n",
    "    \n",
    "    EMUs can be compared based self.metabolite_id and self.atom_nos.\n",
    "    EMU and iterable object of EMUs can also be compared. In this case EMU will be put into\n",
    "    the same iterable object with single item, and comparison between two iterables are performed.\n",
    "    \n",
    "    Currently only binary equivalents are considered.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    id: str\n",
    "        EMU ID\n",
    "    metabolite: Metabolite or str\n",
    "        Which metabolite the EMU comes from.\n",
    "    atom_nos: list of int or str\n",
    "        Atom NOs, sorted by number.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    id: str\n",
    "        EMU ID\n",
    "    metabolite: Metabolite\n",
    "        Which metabolite the EMU comes from.    \n",
    "    metabolite_id: str\n",
    "        Metabolite ID.\n",
    "    atom_nos: list of int\n",
    "        Atom NOs, sorted by number.\n",
    "    size: int\n",
    "        Size of EMU.\n",
    "    equivalent_atom_nos: None or list of int\n",
    "        Equivalent atom NOs, sorted by number.   \n",
    "    equivalent: EMU\n",
    "        Equivalent of EMU.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, id, metabolite, atom_nos):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        id: str\n",
    "            EMU ID\n",
    "        metabolite: Metabolite or str\n",
    "            Which metabolite the EMU comes from.\n",
    "        atom_nos: list of int or str\n",
    "            Atom NOs, sorted by number.\n",
    "        '''\n",
    "        \n",
    "        self.id = id\n",
    "        if isinstance(metabolite, Metabolite):\n",
    "            self.metabolite = metabolite\n",
    "            self.metabolite_id = self.metabolite.id\n",
    "        elif isinstance(metabolite, str):\n",
    "            self.metabolite = Metabolite(metabolite)\n",
    "            self.metabolite_id = metabolite\n",
    "        if isinstance(atom_nos, list):\n",
    "            self.atom_nos = sorted(atom_nos)\n",
    "        elif isinstance(atom_nos, str):\n",
    "            self.atom_nos = sorted(list(map(int, atom_nos)))\n",
    "        self.size = len(self.atom_nos)\n",
    "        \n",
    "    \n",
    "    def __hash__(self):\n",
    "        \n",
    "        return hash(self.metabolite_id) + hash(sum(self.atom_nos))\n",
    "        \n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        other: EMU or iterable\n",
    "        '''\n",
    "        \n",
    "        if isinstance(other, Iterable):\n",
    "            return type(other)([self]) == other\n",
    "        else:\n",
    "            return self.metabolite_id == other.metabolite_id and self.atom_nos == other.atom_nos\n",
    "        \n",
    "        \n",
    "    def __lt__(self, other):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        other: EMU or iterable\n",
    "        '''\n",
    "        \n",
    "        if isinstance(other, Iterable):\n",
    "            return type(other)([self]) < other\n",
    "        else:\n",
    "            if self.metabolite_id != other.metabolite_id:\n",
    "                return self.metabolite_id < other.metabolite_id\n",
    "            else:\n",
    "                return self.atom_nos < other.atom_nos\n",
    "                \n",
    "    \n",
    "    def __gt__(self, other):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        other: EMU or iterable\n",
    "        '''\n",
    "        \n",
    "        if isinstance(other, Iterable):\n",
    "            return type(other)([self]) > other\n",
    "        else:\n",
    "            if self.metabolite_id != other.metabolite_id:\n",
    "                return self.metabolite_id > other.metabolite_id\n",
    "            else:\n",
    "                return self.atom_nos > other.atom_nos\n",
    "        \n",
    "    \n",
    "    @property\n",
    "    @lru_cache()\n",
    "    def equivalent_atom_nos(self):\n",
    "        '''\n",
    "        Returns\n",
    "        -------\n",
    "        equivAtomNOs: list of int or None\n",
    "            Equivalent atom NOs, sorted by number.\n",
    "        '''\n",
    "        \n",
    "        if len(self.metabolite.atoms_info) == 1:\n",
    "            return None\n",
    "\n",
    "        else:\n",
    "            refAtoms, equivAtoms = self.metabolite.atoms_info   \n",
    "            \n",
    "            mapping = dict(zip(refAtoms, range(1, len(refAtoms)+1)))\n",
    "            \n",
    "            equivAtomNOs = sorted([mapping[equivAtoms[no-1]] for no in self.atom_nos])\n",
    "            \n",
    "            if equivAtomNOs == self.atom_nos:\n",
    "                return None\n",
    "            else:\n",
    "                return equivAtomNOs\n",
    "                \n",
    "                \n",
    "    @property\n",
    "    @lru_cache()\n",
    "    def equivalent(self):\n",
    "        '''\n",
    "        Returns\n",
    "        -------\n",
    "        EMU: EMU\n",
    "            Equivalent of current EMU.\n",
    "        '''\n",
    "        \n",
    "        equivAtomNOs = self.equivalent_atom_nos\n",
    "        \n",
    "        if equivAtomNOs:\n",
    "            id = self.metabolite_id + '_' + ''.join(map(str, self.equivalent_atom_nos))\n",
    "            metab = self.metabolite\n",
    "            return EMU(id, metab, equivAtomNOs)\n",
    "        else:\n",
    "            return None\n",
    "            \n",
    "        \n",
    "    def __repr__(self):\n",
    "        \n",
    "        return f'{self.__class__.__name__} {self.metabolite_id}_{\"\".join(map(str, self.atom_nos))}'\n",
    "    \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
